"""
å¯¼å…¥ä¸­å›½æ±½è½¦é”€é‡æ•°æ®åˆ°æ•°æ®åº“
ä» test-data ç›®å½•è¯»å– Excel æ–‡ä»¶å¹¶å¯¼å…¥åˆ° ai-test-data æ•°æ®åº“
"""
import os
import sys
from pathlib import Path
from typing import Dict, Any
import pymysql
import pandas as pd
from colorlog import ColoredFormatter
import logging

from car_sales_ddl import CAR_SALES_TABLES


def get_db_config():
    """ä»ç¯å¢ƒå˜é‡è·å–æ•°æ®åº“é…ç½®"""
    return {
        'host': os.getenv('DB_HOST', 'mariadb'),
        'port': int(os.getenv('DB_PORT', 3306)),
        'database': os.getenv('DB_NAME', 'ai-test-data'),
        'user': os.getenv('DB_USER', 'root'),
        'password': os.getenv('DB_PASSWORD', ''),
    }


def setup_logging():
    """é…ç½®å½©è‰²æ—¥å¿—"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    handler = logging.StreamHandler()
    handler.setLevel(logging.INFO)

    formatter = ColoredFormatter(
        '%(log_color)s%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        log_colors={
            'DEBUG': 'cyan',
            'INFO': 'green',
            'WARNING': 'yellow',
            'ERROR': 'red',
            'CRITICAL': 'red,bg_white',
        }
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    return logger


class CarSalesImporter:
    """æ±½è½¦é”€é‡æ•°æ®å¯¼å…¥å™¨"""

    def __init__(self, db_config: Dict[str, Any], data_dir: str):
        self.db_config = db_config
        self.data_dir = Path(data_dir)
        self.logger = setup_logging()
        self.connection = None

        # Excel æ–‡ä»¶æ˜ å°„åˆ°æ•°æ®åº“è¡¨
        self.file_mapping = {
            'ä¸­å›½æ±½è½¦æ€»ä½“é”€é‡.xlsx': 'car_sales_total',
            'ä¸­å›½æ±½è½¦åˆ†å‚å•†æ¯æœˆé”€å”®è¡¨.xlsx': 'car_sales_by_manufacturer',
            'ä¸­å›½æ±½è½¦åˆ†è½¦å‹æ¯æœˆé”€å”®é‡.xlsx': 'car_sales_by_model'
        }

    def connect(self):
        """è¿æ¥åˆ°æ•°æ®åº“"""
        try:
            self.connection = pymysql.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                user=self.db_config['user'],
                password=self.db_config['password'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            self.logger.info(f"âœ… å·²è¿æ¥åˆ° MariaDB: {self.db_config['host']}:{self.db_config['port']}")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            self.logger.info("ğŸ“Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def use_database(self):
        """åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“"""
        try:
            db_name = self.db_config['database']
            with self.connection.cursor() as cursor:
                cursor.execute(f"USE `{db_name}`")
                self.logger.info(f"ğŸ“ ä½¿ç”¨æ•°æ®åº“: {db_name}")
        except Exception as e:
            self.logger.error(f"âŒ åˆ‡æ¢æ•°æ®åº“å¤±è´¥: {e}")
            raise

    def create_tables(self):
        """åˆ›å»ºæ‰€æœ‰æ±½è½¦é”€é‡æ•°æ®è¡¨"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‹ åˆ›å»ºæ±½è½¦é”€é‡æ•°æ®è¡¨")
        self.logger.info("="*60 + "\n")

        for table_name, ddl in CAR_SALES_TABLES.items():
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute(ddl)
                    self.connection.commit()
                    self.logger.info(f"âœ… è¡¨ '{table_name}' åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ è¡¨ '{table_name}' åˆ›å»ºè­¦å‘Š: {e}")

    def process_car_sales_total(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†æ€»ä½“é”€é‡æ•°æ®"""
        self.logger.info("ğŸ”„ å¤„ç†æ€»ä½“é”€é‡æ•°æ®...")

        # é‡å‘½ååˆ—
        df_processed = df.copy()
        df_processed.columns = ['sale_date', 'sales_volume', 'year_on_year']

        # ç¡®ä¿ sale_date æ˜¯æ—¥æœŸç±»å‹
        df_processed['sale_date'] = pd.to_datetime(df_processed['sale_date'])

        # åˆ é™¤ NaN è¡Œ
        df_processed = df_processed.dropna(subset=['sale_date', 'sales_volume'])

        self.logger.info(f"   å¤„ç†å: {len(df_processed)} è¡Œ")
        return df_processed

    def process_car_sales_by_manufacturer(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†åˆ†å‚å•†é”€é‡æ•°æ®"""
        self.logger.info("ğŸ”„ å¤„ç†åˆ†å‚å•†é”€é‡æ•°æ®...")

        # é‡å‘½ååˆ—
        df_processed = df.copy()
        df_processed.columns = ['year', 'month', 'ranking', 'logo_url',
                                'manufacturer', 'sales_volume', 'market_share']

        # åˆ é™¤ NaN è¡Œ
        df_processed = df_processed.dropna(subset=['year', 'month', 'manufacturer'])

        # æ¸…ç†å¸‚åœºä»½é¢æ•°æ® (å»æ‰ % ç¬¦å·)
        if 'market_share' in df_processed.columns:
            df_processed['market_share'] = df_processed['market_share'].astype(str).str.replace('%', '').str.strip()

        self.logger.info(f"   å¤„ç†å: {len(df_processed)} è¡Œ")
        return df_processed

    def process_car_sales_by_model(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†åˆ†è½¦å‹é”€é‡æ•°æ®"""
        self.logger.info("ğŸ”„ å¤„ç†åˆ†è½¦å‹é”€é‡æ•°æ®...")

        # é‡å‘½ååˆ—
        df_processed = df.copy()
        df_processed.columns = ['year', 'month', 'ranking', 'car_model',
                                'manufacturer', 'sales_volume', 'price_range']

        # åˆ é™¤ NaN è¡Œ
        df_processed = df_processed.dropna(subset=['year', 'month', 'car_model'])

        self.logger.info(f"   å¤„ç†å: {len(df_processed)} è¡Œ")
        return df_processed

    def import_file(self, file_path: str, table_name: str):
        """å¯¼å…¥å•ä¸ªæ–‡ä»¶"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ“¥ å¯¼å…¥æ–‡ä»¶: {Path(file_path).name}")
        self.logger.info(f"ğŸ“‹ ç›®æ ‡è¡¨: {table_name}")
        self.logger.info(f"{'='*60}\n")

        # è¯»å– Excel
        try:
            df = pd.read_excel(file_path)
            self.logger.info(f"ğŸ“– è¯»å–æˆåŠŸ: {len(df)} è¡Œ x {len(df.columns)} åˆ—")
        except Exception as e:
            self.logger.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return

        # æ ¹æ®è¡¨åå¤„ç†æ•°æ®
        if table_name == 'car_sales_total':
            df_processed = self.process_car_sales_total(df)
        elif table_name == 'car_sales_by_manufacturer':
            df_processed = self.process_car_sales_by_manufacturer(df)
        elif table_name == 'car_sales_by_model':
            df_processed = self.process_car_sales_by_model(df)
        else:
            self.logger.error(f"âŒ æœªçŸ¥çš„è¡¨å: {table_name}")
            return

        # è·å–è¡¨çš„å®é™…åˆ—
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(f"DESCRIBE `{table_name}`")
                table_columns = set(row['Field'] for row in cursor.fetchall())
        except Exception as e:
            self.logger.error(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
            return

        # è¿‡æ»¤å‡ºè¡¨ä¸­å­˜åœ¨çš„åˆ—ï¼ˆæ’é™¤ id, created_at, updated_atï¼‰
        exclude_columns = {'id', 'created_at', 'updated_at'}
        valid_columns = [col for col in df_processed.columns
                        if col in table_columns and col not in exclude_columns]

        df_filtered = df_processed[valid_columns].copy()

        # å‡†å¤‡æ’å…¥æ•°æ®
        columns = df_filtered.columns.tolist()
        placeholders = ', '.join(['%s'] * len(columns))

        # æ„å»ºåˆ—åå’Œæ›´æ–°å­å¥
        col_names = ', '.join([f'`{col}`' for col in columns])
        exclude_cols = {'year', 'month', 'ranking', 'car_model', 'manufacturer'}
        update_cols = [f"`{col}`=VALUES(`{col}`)" for col in columns if col not in exclude_cols]
        update_clause = ', '.join(update_cols)

        sql = f"""
            INSERT INTO `{table_name}` ({col_names})
            VALUES ({placeholders})
            ON DUPLICATE KEY UPDATE {update_clause}
        """

        # æ‰¹é‡æ’å…¥
        batch_size = 1000
        total_rows = len(df_filtered)
        success_count = 0

        self.logger.info(f"ğŸ”„ å¼€å§‹å¯¼å…¥æ•°æ® ({total_rows} è¡Œ)...")

        for i in range(0, total_rows, batch_size):
            batch = df_filtered.iloc[i:i + batch_size]

            # å¤„ç† NaN å€¼ï¼ˆè½¬ä¸º NULLï¼‰
            batch_clean = batch.where(pd.notnull(batch), None)

            # è½¬æ¢ä¸ºåˆ—è¡¨
            values = [tuple(row) for row in batch_clean.values]

            try:
                with self.connection.cursor() as cursor:
                    cursor.executemany(sql, values)
                    self.connection.commit()
                    success_count += len(values)
            except Exception as e:
                self.connection.rollback()
                self.logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥ (è¡Œ {i}-{i+len(values)}): {e}")

        self.logger.info(f"âœ… å¯¼å…¥å®Œæˆ: æˆåŠŸ {success_count} è¡Œ")

        # æ˜¾ç¤ºè¡¨ä¸­è®°å½•æ•°
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(f"SELECT COUNT(*) as count FROM `{table_name}`")
                count = cursor.fetchone()['count']
                self.logger.info(f"ğŸ“Š è¡¨ '{table_name}' å½“å‰è®°å½•æ•°: {count:,}")
        except Exception as e:
            self.logger.error(f"âŒ è·å–è®°å½•æ•°å¤±è´¥: {e}")

    def import_all(self):
        """å¯¼å…¥æ‰€æœ‰æ±½è½¦é”€é‡æ•°æ®"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸš— å¼€å§‹å¯¼å…¥ä¸­å›½æ±½è½¦é”€é‡æ•°æ®")
        self.logger.info("="*60 + "\n")

        # æ£€æŸ¥æ•°æ®ç›®å½•
        if not self.data_dir.exists():
            self.logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
            return

        # åˆ›å»ºè¡¨
        self.create_tables()

        # å¯¼å…¥æ¯ä¸ªæ–‡ä»¶
        for file_name, table_name in self.file_mapping.items():
            file_path = self.data_dir / file_name
            if file_path.exists():
                self.import_file(str(file_path), table_name)
            else:
                self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        self.logger.info("\n" + "="*60)
        self.logger.info("âœ… æ‰€æœ‰æ±½è½¦é”€é‡æ•°æ®å¯¼å…¥å®Œæˆï¼")
        self.logger.info("="*60 + "\n")


def main():
    # è·å–æ•°æ®åº“é…ç½®
    db_config = get_db_config()

    # æ•°æ®ç›®å½•ï¼ˆåœ¨å®¹å™¨å†…ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
    data_dir = Path('/app/test-data')

    # åˆ›å»ºå¯¼å…¥å™¨
    importer = CarSalesImporter(db_config, str(data_dir))

    try:
        # è¿æ¥æ•°æ®åº“
        importer.connect()
        importer.use_database()

        # å¯¼å…¥æ‰€æœ‰æ•°æ®
        importer.import_all()

    except Exception as e:
        logging.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        importer.close()


if __name__ == '__main__':
    main()
